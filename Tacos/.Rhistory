d_test <- d[-train,]
mod_pcr <-  pcr(Rating~., data = d_train, scale = TRUE, validation = "CV")
summary(mod_pcr)
View(abs(mod_pcr$coefficients))
pcr_pred <- predict(mod_pcr, d_test, ncomp = 10)
cor((pcr_pred - d_test$Rating)^2)
cor((pcr_pred,d_test$Rating)^2)
cor(pcr_pred,d_test$Rating)^2
cor(pcr_pred,d_test$Rating)
cor(pcr_pred,d_test$Rating)^2
d_test <- pcr_pred
train <- sample(length(d$Restaurant),0.8*length(d$restaurant.1))
d_train <- d[train,]
d_test <- d[-train,]
mod_pcr <-  pcr(Rating~., data = d_train, scale = TRUE, validation = "CV")
summary(mod_pcr)
pcr_pred <- predict(mod_pcr, d_test, ncomp = 10)
cor(pcr_pred,d_test$Rating)^2
d_test$pred <- pcr_pred
d_test$error <- d_test$Rating - d_test$pred
mean(d_test$error)
quantile(d_test$error)
mean(abs(d_test$error))
View(rest)
#Analize outliers
d <- d %>% select_if(Restaurant=="Donna")
#Analize outliers
d <- d %>% filter(Restaurant=="Donna")
d
library(stringi)
#Analize outliers
d <- d %>% filter(stri_detect_fixed(Restaurant,"Donna"))
d
View(d)
library(readxl)
library(tidyverse)
library(pls)
library(dplyr)
library(stringi)
d <- read_excel("tacos.xlsx",sheet = "Data")
rest <- d %>% group_by(Restaurant) %>% summarise(Rating=mean(Rating))
rest
mod <- lm(Rating~.-Restaurant,data=d)
summary(mod)
d_num <- select_if(d,is.numeric)
d_num
mod_pcr <-  pcr(Rating~., data = d_num, scale = TRUE, validation = "CV")
summary(mod_pcr)
mod_pcr$Xmeans
View(abs(mod_pcr$coefficients))
d <- d %>% mutate_all(as.factor) %>% mutate_all(as.numeric)
str(d)
mod_pcr <-  pcr(Rating~., data = d, scale = TRUE, validation = "CV")
summary(mod_pcr)
View(abs(mod_pcr$coefficients))
#training and testing
train <- sample(length(d$Restaurant),0.8*length(d$restaurant.1))
d_train <- d[train,]
d_test <- d[-train,]
mod_pcr <-  pcr(Rating~., data = d_train, scale = TRUE, validation = "CV")
summary(mod_pcr)
pcr_pred <- predict(mod_pcr, d_test, ncomp = 10)
cor(pcr_pred,d_test$Rating)^2
d_test$pred <- pcr_pred
d_test$error <- d_test$Rating - d_test$pred
mean(abs(d_test$error))
quantile(d_test$error)
d <- read_excel("tacos.xlsx",sheet = "Data")
#Analize outliers
d <- d %>% filter(stri_detect_fixed(Restaurant,"Donna"))
d
table(d$food)
summarise_all(d[,2:40])
d[,2:40] %>%summarise_all("mean")
View(d[,2:40] %>%summarise_all("mean"))
mean_donna <-d[,2:40] %>%summarise_all("mean")
mean_donna
View(mean_donna)
mean_donna <- t(mean_donna)
mean_donna
max(mean_donna,5)
head(max(mean_donna),5)
mean_donna[order(mean_donna)[1:5]]
mean_donna[order(mean_donna)[35:40]]
mean_donna[order(mean_donna)]
#Analize outliers
d <- d %>% filter(stri_detect_fixed(Restaurant,"Donna"))
d
mean_donna <-d[,2:40] %>%summarise_all("mean")
mean_donna <- t(mean_donna)
mean_donna
mean_donna <- data.frame(t(mean_donna))
View(mean_donna)
#Analize outliers
d <- d %>% filter(stri_detect_fixed(Restaurant,"Donna"))
d
mean_donna <-d[,2:40] %>%summarise_all("mean")
mean_donna <- t(mean_donna)
mean_donna <- data.frame(mean_donna)
View(mean_donna)
View(rest)
d <- d %>% filter(stri_detect_fixed(Restaurant,"Arriba Arriba Sunnyside	"))
d
d <- d %>% filter(stri_detect_fixed(Restaurant,"Arriba Arriba Sunnyside"))
d
d <- read_excel("tacos.xlsx",sheet = "Data")
d <- d %>% filter(stri_detect_fixed(Restaurant,"Arriba Arriba Sunnyside"))
d
d <- read_excel("tacos.xlsx",sheet = "Data")
d <- d %>% filter(stri_detect_fixed(Restaurant,"Arriba Arriba Sunnyside"))
d
mean_donna <-d[,2:40] %>%summarise_all("mean")
mean_donna <- t(mean_donna)
mean_donna <- data.frame(mean_donna)
View(mean_donna)
d <- read_excel("tacos.xlsx",sheet = "Data")
d <- d %>% filter(stri_detect_fixed(Restaurant,"Donna"))
d
mean_donna <-d[,2:40] %>%summarise_all("mean")
mean_donna <- t(mean_donna)
mean_donna <- data.frame(mean_donna)
View(mean_donna)
d <- read_excel("tacos.xlsx",sheet = "Data")
d <- d %>% filter(stri_detect_fixed(Restaurant,"Donna"))
d
mean_donna <-d[,2:40] %>%summarise_all("mean")
mean_donna <- t(mean_donna)
mean_donna <- data.frame(mean_donna)
max(mean_donna,5)
mean_donna[order(mean_donna)]
d <- read_excel("tacos.xlsx",sheet = "Data")
d <- d %>% filter(stri_detect_fixed(Restaurant,"Arriba Arriba Sunnyside"))
d
mean_arriba <-d[,2:40] %>%summarise_all("mean")
mean_arriba <- t(mean_donna)
mean_arriba <- data.frame(mean_donna)
max(mean_donna,5)
mean_donna[order(mean_donna)]
#Analize outliers
d <- read_excel("tacos.xlsx",sheet = "Data")
d <- d %>% filter(stri_detect_fixed(Restaurant,"Donna"))
d
#Analize outliers
d <- read_excel("tacos.xlsx",sheet = "Data")
d <- d %>% filter(stri_detect_fixed(Restaurant,"Donna"))
d
mean_donna <-d[,2:40] %>%summarise_all("mean")
mean_donna <- t(mean_donna)
mean_donna <- data.frame(mean_donna)
View(mean_donna)
View(mean_arriba)
d <- read_excel("tacos.xlsx",sheet = "Data")
d <- d %>% filter(stri_detect_fixed(Restaurant,"Arriba Arriba Sunnyside"))
d
mean_arriba <-d[,2:40] %>%summarise_all("mean")
mean_arriba <- t(mean_donna)
mean_arriba <- data.frame(mean_arriba)
View(mean_donna)
View(mean_arriba)
d <- read_excel("tacos.xlsx",sheet = "Data")
d <- d %>% filter(stri_detect_fixed(Restaurant,"Arriba Arriba Sunnyside"))
d
mean_arriba <-d[,2:40] %>%summarise_all("mean")
mean_arriba <- t(mean_arriba)
mean_arriba <- data.frame(mean_arriba)
View(mean_arriba)
#drinks
d <- read_excel("tacos.xlsx",sheet = "Data")
library(readxl)
library(tidyverse)
library(pls)
library(dplyr)
library(stringi)
#drinks
d <- read_excel("tacos.xlsx",sheet = "Data")
View(d)
drinks <- d %>% filter(drink==1)
mean(drinks$Rating)
View(d)
View(drinks)
library(readxl)
library(tidyverse)
library(pls)
library(dplyr)
library(stringi)
d <- read_excel("tacos.xlsx",sheet = "Data")
rest <- d %>% group_by(Restaurant) %>% summarise(Rating=mean(Rating))
rest
mod <- lm(Rating~.-Restaurant,data=d)
summary(mod)
d_num <- select_if(d,is.numeric)
d_num
mod_pcr <-  pcr(Rating~., data = d_num, scale = TRUE, validation = "CV")
summary(mod_pcr)
mod_pcr$Xmeans
View(abs(mod_pcr$coefficients))
d <- d %>% mutate_all(as.factor) %>% mutate_all(as.numeric)
str(d)
mod_pcr <-  pcr(Rating~., data = d, scale = TRUE, validation = "CV")
summary(mod_pcr)
View(abs(mod_pcr$coefficients))
#training and testing
train <- sample(length(d$Restaurant),0.8*length(d$restaurant.1))
d_train <- d[train,]
d_test <- d[-train,]
mod_pcr <-  pcr(Rating~., data = d_train, scale = TRUE, validation = "CV")
summary(mod_pcr)
pcr_pred <- predict(mod_pcr, d_test, ncomp = 10)
cor(pcr_pred,d_test$Rating)^2
d_test$pred <- pcr_pred
d_test$error <- d_test$Rating - d_test$pred
mean(abs(d_test$error))
quantile(d_test$error)
#Analize outliers
d <- read_excel("tacos.xlsx",sheet = "Data")
d <- d %>% filter(stri_detect_fixed(Restaurant,"Donna"))
d
mean_donna <-d[,2:40] %>%summarise_all("mean")
mean_donna <- t(mean_donna)
mean_donna <- data.frame(mean_donna)
max(mean_donna,5)
mean_donna[order(mean_donna)]
d <- read_excel("tacos.xlsx",sheet = "Data")
d <- d %>% filter(stri_detect_fixed(Restaurant,"Arriba Arriba Sunnyside"))
d
mean_arriba <-d[,2:40] %>%summarise_all("mean")
mean_arriba <- t(mean_arriba)
mean_arriba <- data.frame(mean_arriba)
mean_donna[order(mean_donna)]
#drinks
d <- read_excel("tacos.xlsx",sheet = "Data")
drinks <- d %>% filter(drink==1)
mean(drinks$Rating)
View(mean_donna)
View(mean_arriba)
View(mean_arriba)
View(mean_donna)
cor(d[2:40])
View(abs(cor(d[2:40])))
View(cor(d[2:40]))
#Web scrapping
library(rvest)
install.packages("rvest")
install.packages("rvest")
library(stringr)
library(readxl)
library(writexl)
library(tidyverse)
#Website
url1 <- 'https://www.yelp.com/biz/villalobos-montclair'
url2 <- 'https://www.yelp.com/biz/donna-brooklyn'
url4 <- 'https://www.yelp.com/biz/bennys-burritos-new-york'
url5 <- 'https://www.yelp.com/biz/la-esquina-soho-new-york'
url <- c(url1,url2,url3,url4,url5)
url3 <- 'https://www.yelp.com/biz/poketeria-new-york'
url <- c(url1,url2,url3,url4,url5)
data <- data.frame()
#get title
title_htlm <- htlm_nodes(webpage,'h1')
library(rvest)
library(stringr)
library(readxl)
library(writexl)
library(tidyverse)
#Web scraping
#get title
title_htlm <- htlm_nodes(webpage,'h1')
#Web scrapping
library(rvest)
#get title
title_htlm <- html_nodes(webpage,'h1')
library(stringr)
for(url in url){
#read HTLM
webpage <- read_htlm(url)
#get title
title_htlm <- html_nodes(webpage,'h1')
title <- html_text(title_htlm)
title <- str_trim(title)[1]
#get adress
address_htlm <- html_nodes(webpage,'address')
adress <-html_text(address_htlm)
adress <- str_trim(adress)[1]
#get rating
rate_htlm <- html_nodes(webpage,"  <div class="lemon--div__373c0__1mboc u-space-b1 u-padding-t2 u-padding-r2 u-padding-b2 u-padding-l2 border--top__373c0__19Owr border-color--default__373c0__2oFDT background-color--gray-extra-light__373c0__vNfIZ"><div class="lemon--div__373c0__1mboc arrange__373c0__UHqhV gutter-12__373c0__3kguh vertical-align-middle__373c0__2TQsQ border-color--default__373c0__2oFDT"><div class="lemon--div__373c0__1mboc arrange-unit__373c0__1piwO border-color--default__373c0__2oFDT"><span class="lemon--span__373c0__3997G icon__373c0__ehCWV icon--24-yelp icon--red-dark__373c0__2hANf" aria-hidden="true" style="width:24px;height:24px"><svg xmlns="http://www.w3.org/2000/svg" class="icon_svg" viewBox="0 0 24 24" width="24" height="24"><path d="M 18.803 12.49 l -4.162 1.194 c -0.8 0.23 -1.45 -0.666 -0.98 -1.357 l 2.42 -3.59 a 0.893 0.893 0 0 1 1.33 -0.172 a 7.66 7.66 0 0 1 1.97 2.71 a 0.894 0.894 0 0 1 -0.572 1.215 Z m -4.187 2.627 l 4.117 1.338 a 0.893 0.893 0 0 1 0.53 1.233 a 7.762 7.762 0 0 1 -2.058 2.64 a 0.894 0.894 0 0 1 -1.326 -0.216 l -2.3 -3.674 c -0.44 -0.706 0.24 -1.578 1.03 -1.32 Z m -3.996 -3.64 l -4.07 -7.05 a 0.893 0.893 0 0 1 0.388 -1.25 A 12.475 12.475 0 0 1 11.324 2 c 0.518 -0.04 0.96 0.37 0.96 0.89 v 8.138 c 0 0.913 -1.208 1.236 -1.664 0.446 Z m -0.714 3.475 L 5.704 16 a 0.894 0.894 0 0 1 -1.103 -0.767 a 7.68 7.68 0 0 1 0.358 -3.33 a 0.892 0.892 0 0 1 1.237 -0.516 l 3.89 1.898 c 0.75 0.365 0.635 1.466 -0.173 1.667 Z m 0.738 1.23 c 0.557 -0.62 1.584 -0.205 1.555 0.627 l -0.158 4.322 c -0.02 0.54 -0.51 0.94 -1.04 0.85 A 7.76 7.76 0 0 1 7.9 20.73 a 0.893 0.893 0 0 1 -0.156 -1.333 l 2.897 -3.22 Z" /></svg></span></div><div class="lemon--div__373c0__1mboc arrange-unit__373c0__1piwO arrange-unit-fill__373c0__17z0h border-color--default__373c0__2oFDT"><p class="lemon--p__373c0__3Qnnj text__373c0__2pB8f text__373c0__7Srzf text-color--normal__373c0__K_MKN text-align--left__373c0__2pnx_ text-size--small__373c0__3SGMi"><span class="lemon--span__373c0__3997G"><b>Your trust is our top concern,</b> so businesses can't pay to alter or remove their reviews. <a href="/advertiser_faq">Learn more.</a></span></p></div><div class="lemon--div__373c0__1mboc arrange-unit__373c0__1piwO border-color--default__373c0__2oFDT"><p class="lemon--p__373c0__3Qnnj text__373c0__2pB8f text-color--normal__373c0__K_MKN text-align--right__373c0__3ARv7"><a tabindex="0" class="lemon--a__373c0__IEZFH dismiss-link__373c0__3xvNi light__373c0__2qT0e" role="button" aria-label="Close"><span class="lemon--span__373c0__3997G">×</span></a></p></div></div></div>
")
rate <- str_match(rate_htlm,"[0-9].[0-9] estrellas")
rate <- str_trim(rate)[1]
#data frame
d <- data.frame(restaurant=title,address=adress,rating=rate)
data <- rbind(data,d)
}
data
for(url in url){
#read HTLM
webpage <- read_htlm(url)
#get title
title_htlm <- html_nodes(webpage,'h1')
title <- html_text(title_htlm)
title <- str_trim(title)[1]
#get adress
address_htlm <- html_nodes(webpage,'address')
adress <-html_text(address_htlm)
adress <- str_trim(adress)[1]
#get rating
rate_htlm <- html_nodes(webpage,"  <div class="lemon--div__373c0__1mboc u-space-b1 u-padding-t2 u-padding-r2 u-padding-b2 u-padding-l2 border--top__373c0__19Owr border-color--default__373c0__2oFDT background-color--gray-extra-light__373c0__vNfIZ"><div class="lemon--div__373c0__1mboc arrange__373c0__UHqhV gutter-12__373c0__3kguh vertical-align-middle__373c0__2TQsQ border-color--default__373c0__2oFDT"><div class="lemon--div__373c0__1mboc arrange-unit__373c0__1piwO border-color--default__373c0__2oFDT"><span class="lemon--span__373c0__3997G icon__373c0__ehCWV icon--24-yelp icon--red-dark__373c0__2hANf" aria-hidden="true" style="width:24px;height:24px"><svg xmlns="http://www.w3.org/2000/svg" class="icon_svg" viewBox="0 0 24 24" width="24" height="24"><path d="M 18.803 12.49 l -4.162 1.194 c -0.8 0.23 -1.45 -0.666 -0.98 -1.357 l 2.42 -3.59 a 0.893 0.893 0 0 1 1.33 -0.172 a 7.66 7.66 0 0 1 1.97 2.71 a 0.894 0.894 0 0 1 -0.572 1.215 Z m -4.187 2.627 l 4.117 1.338 a 0.893 0.893 0 0 1 0.53 1.233 a 7.762 7.762 0 0 1 -2.058 2.64 a 0.894 0.894 0 0 1 -1.326 -0.216 l -2.3 -3.674 c -0.44 -0.706 0.24 -1.578 1.03 -1.32 Z m -3.996 -3.64 l -4.07 -7.05 a 0.893 0.893 0 0 1 0.388 -1.25 A 12.475 12.475 0 0 1 11.324 2 c 0.518 -0.04 0.96 0.37 0.96 0.89 v 8.138 c 0 0.913 -1.208 1.236 -1.664 0.446 Z m -0.714 3.475 L 5.704 16 a 0.894 0.894 0 0 1 -1.103 -0.767 a 7.68 7.68 0 0 1 0.358 -3.33 a 0.892 0.892 0 0 1 1.237 -0.516 l 3.89 1.898 c 0.75 0.365 0.635 1.466 -0.173 1.667 Z m 0.738 1.23 c 0.557 -0.62 1.584 -0.205 1.555 0.627 l -0.158 4.322 c -0.02 0.54 -0.51 0.94 -1.04 0.85 A 7.76 7.76 0 0 1 7.9 20.73 a 0.893 0.893 0 0 1 -0.156 -1.333 l 2.897 -3.22 Z" /></svg></span></div><div class="lemon--div__373c0__1mboc arrange-unit__373c0__1piwO arrange-unit-fill__373c0__17z0h border-color--default__373c0__2oFDT"><p class="lemon--p__373c0__3Qnnj text__373c0__2pB8f text__373c0__7Srzf text-color--normal__373c0__K_MKN text-align--left__373c0__2pnx_ text-size--small__373c0__3SGMi"><span class="lemon--span__373c0__3997G"><b>Your trust is our top concern,</b> so businesses can't pay to alter or remove their reviews. <a href="/advertiser_faq">Learn more.</a></span></p></div><div class="lemon--div__373c0__1mboc arrange-unit__373c0__1piwO border-color--default__373c0__2oFDT"><p class="lemon--p__373c0__3Qnnj text__373c0__2pB8f text-color--normal__373c0__K_MKN text-align--right__373c0__3ARv7"><a tabindex="0" class="lemon--a__373c0__IEZFH dismiss-link__373c0__3xvNi light__373c0__2qT0e" role="button" aria-label="Close"><span class="lemon--span__373c0__3997G">×</span></a></p></div></div></div>
")
rate <- str_match(rate_htlm,"[0-9].[0-9] estrellas")
rate <- str_trim(rate)[1]
#data frame
d <- data.frame(restaurant=title,address=adress,rating=rate)
data <- rbind(data,d)
}
View(mean_arriba)
mean_arriba <-d[,2:40] %>%summarise_all("cor")
mean_arriba <-d[,2:40] %>%summarise_all("correlation")
cor(d[2:40])
View(cor(d[2:40]))
View(mean_arriba)
View(mean_arriba)
View(mean_donna)
# Tacos (Yelp)
library(rvest)    # web scraping
library(stringr)  # manipulate text
library(readxl)
library(writexl)
library(tidyverse)
# web scraping ------------------------------------------------------------
# website
url1 <- 'https://www.yelp.es/biz/villalobos-montclair?osq=villalobos'
url2 <- 'https://www.yelp.es/biz/donna-brooklyn?osq=donna'
url3 <- 'https://www.yelp.es/biz/poketeria-new-york'
url4 <- 'https://www.yelp.es/biz/bennys-burritos-new-york'
url5 <- 'https://www.yelp.es/biz/la-esquina-soho-new-york?osq=La+esquina'
url6 <- 'https://www.yelp.es/biz/arriba-arriba-sunnyside-sunnyside-111?osq=Arriba+Arriba+Sunnyside'
url7 <- 'https://www.yelp.es/biz/dylan-murphys-new-york?osq=dylan+murphys'
url <- c(url1,url2,url3,url4,url5,url6,url7)
data <-  data.frame()
for (url in url) {
# read HTML content
webpage <- read_html(url)
# get title
title_html <- html_nodes(webpage,'h1')
title <- html_text(title_html)
title <- str_trim(title)
# get address
address_html <- html_nodes(webpage,'address')
address <- html_text(address_html)
address <- str_trim(address)[1]
# get rating
rate_html <- html_nodes(webpage, "[class='lemon--div__373c0__1mboc border-color--default__373c0__2oFDT']")
rate <- str_match(rate_html,"[0-9].[0-9] estrellas")
rate <- str_trim(rate)[1]
# data frame
d <- data.frame(restaurant = title, address=address, rating = rate)
data <- rbind(data,d)
}
data
data$rating <- substr(data$rating, 0, 3) # take first three characters
# export as xlsx
write_xlsx(data,"scrape_test.xlsx")
# data analysis -----------------------------------------------------------
# count words
d <- read_xlsx("tacos.xlsx", sheet ="Reviews")
d$Food <-  str_count(d$Review, c("Food"))
d$Good <-  str_count(d$Review, c("Good"))
# import data
d <- read_xlsx("tacos.xlsx", sheet="Data")
d <- d %>% rename(rest=Restaurant, rating=Rating)
# descriptive
hist(d$rating, breaks = seq(0,5))
table(d$rating)
d %>% group_by(rest) %>% summarise(rating=mean(rating))
# rating by restaurant - table
x <- d %>%
group_by(rest) %>%
summarise(table=list(table(rating)))
x$table
# rating by restaurant - histogram
histogram <- d %>%
group_by(rest) %>%
summarise(histogram=list(hist(rating, plot=TRUE)))
# correlation with rating
correl <- round(cor(d[,-1])[,1],2)
sort(correl)
# competitor profiling
profile <- d %>%
split(.$rest) %>%
map(select, -c(rest)) %>%
map(cor) # correlation split by restaurant
profile_df <- round(as.data.frame(profile),3)
profile_df[c(1,40,79,118,157)] # select rating only
write.csv(profile_df, "cors.csv")
data
# Tacos (Yelp)
library(rvest)    # web scraping
library(stringr)  # manipulate text
library(readxl)
library(writexl)
library(tidyverse)
# web scraping ------------------------------------------------------------
# website
url1 <- 'https://www.yelp.es/biz/villalobos-montclair?osq=villalobos'
url2 <- 'https://www.yelp.es/biz/donna-brooklyn?osq=donna'
url3 <- 'https://www.yelp.es/biz/poketeria-new-york'
url4 <- 'https://www.yelp.es/biz/bennys-burritos-new-york'
url5 <- 'https://www.yelp.es/biz/la-esquina-soho-new-york?osq=La+esquina'
url6 <- 'https://www.yelp.es/biz/arriba-arriba-sunnyside-sunnyside-111?osq=Arriba+Arriba+Sunnyside'
url7 <- 'https://www.yelp.es/biz/dylan-murphys-new-york?osq=dylan+murphys'
url <- c(url1,url2,url3,url4,url5,url6,url7)
data <-  data.frame()
for (url in url) {
# read HTML content
webpage <- read_html(url)
# get title
title_html <- html_nodes(webpage,'h1')
title <- html_text(title_html)
title <- str_trim(title)
# get address
address_html <- html_nodes(webpage,'address')
address <- html_text(address_html)
address <- str_trim(address)[1]
# get rating
rate_html <- html_nodes(webpage, "[class='lemon--div__373c0__1mboc border-color--default__373c0__2oFDT']")
rate <- str_match(rate_html,"[0-9].[0-9] estrellas")
rate <- str_trim(rate)[1]
# data frame
d <- data.frame(restaurant = title, address=address, rating = rate)
data <- rbind(data,d)
}
data
data$rating <- substr(data$rating, 0, 3) # take first three characters
# export as xlsx
write_xlsx(data,"scrape_test.xlsx")
# data analysis -----------------------------------------------------------
# count words
d <- read_xlsx("tacos.xlsx", sheet ="Reviews")
d$Food <-  str_count(d$Review, c("Food"))
d$Good <-  str_count(d$Review, c("Good"))
# import data
d <- read_xlsx("tacos.xlsx", sheet="Data")
d <- d %>% rename(rest=Restaurant, rating=Rating)
# descriptive
hist(d$rating, breaks = seq(0,5))
table(d$rating)
d %>% group_by(rest) %>% summarise(rating=mean(rating))
# rating by restaurant - table
x <- d %>%
group_by(rest) %>%
summarise(table=list(table(rating)))
x$table
# rating by restaurant - histogram
histogram <- d %>%
group_by(rest) %>%
summarise(histogram=list(hist(rating, plot=TRUE)))
# correlation with rating
correl <- round(cor(d[,-1])[,1],2)
sort(correl)
# competitor profiling
profile <- d %>%
split(.$rest) %>%
map(select, -c(rest)) %>%
map(cor) # correlation split by restaurant
profile_df <- round(as.data.frame(profile),3)
profile_df[c(1,40,79,118,157)] # select rating only
write.csv(profile_df, "cors.csv")
data
# export as xlsx
write_xlsx(data,"scrape_test.xlsx")
# count words
d <- read_xlsx("tacos.xlsx", sheet ="Reviews")
d$Food <-  str_count(d$Review, c("Food"))
d$Good <-  str_count(d$Review, c("Good"))
View(d)
d$Food <-  str_count(d$Review, c("FOod"))
View(d)
d$Food <-  str_count(d$Review, c("food"))
View(d)
# import data
d <- read_xlsx("tacos.xlsx", sheet="Data")
d <- d %>% rename(rest=Restaurant, rating=Rating)
# descriptive
hist(d$rating, breaks = seq(0,5))
table(d$rating)
d %>% group_by(rest) %>% summarise(rating=mean(rating))
# rating by restaurant - table
x <- d %>%
group_by(rest) %>%
summarise(table=list(table(rating)))
x$table
# rating by restaurant - histogram
histogram <- d %>%
group_by(rest) %>%
summarise(histogram=list(hist(rating, plot=TRUE)))
# correlation with rating
correl <- round(cor(d[,-1])[,1],2)
44+14+37+47+30
172/5
View(x)
sort(correl)
View(sort(correl))
View(profile)
profile$`Arriba Arriba Sunnyside`
profile$Villalobos
View(profile$`Arriba Arriba Sunnyside`)
View(d)
profile_df <- round(as.data.frame(profile),3)
profile_df
View(profile_df)
profile_df[c(1,40,79,118,157)] # select rating only
write.csv(profile_df, "cors.csv")
data
